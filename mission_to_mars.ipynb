{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_content(url):\n",
    "    exe_path = {\"executable_path\": \"./bin/chromedriver\"}\n",
    "\n",
    "    with Browser(\"chrome\", **exe_path, headless=True) as browser:\n",
    "        browser.visit(url)\n",
    "        content = browser.html\n",
    "        return BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    \n",
    "def memoized(value, storage):\n",
    "    if value not in storage:\n",
    "        storage[value] = value\n",
    "        return storage[value]\n",
    "    return ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scrape the content for Mars news:\n",
    "news_content = get_soup_content(\"https://mars.nasa.gov/news/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Data Wrangling for Mars news: \n",
    "\n",
    "content = news_content.find_all(class_=\"list_text\")\n",
    "\n",
    "# Get final response:\n",
    "news_title = [element.find(class_=\"content_title\").get_text() for element in content if element.find(class_=\"content_title\")]\n",
    "news_p = [element.find(class_=\"article_teaser_body\").get_text() for element in content if element.find(class_=\"article_teaser_body\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the content for Mars feature image:\n",
    "jpl_content = get_soup_content(\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling for Mars feature image:\n",
    "featured_image_url = jpl_content.find(class_=\"carousel_item\")[\"style\"].split(\":\")[1].split(\"'\")[1]\n",
    "\n",
    "# Final response:\n",
    "featured_image_url = \"https://www.jpl.nasa.gov{}\".format(jpl_style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the content for Mars tweets:\n",
    "tweet_content = get_soup_content(\"https://twitter.com/marswxreport?lang=en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling for Mars tweets:\n",
    "mars_weather = tweet_content.find(class_=\"TweetTextSize\").get_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the content for Mars facts:\n",
    "facts_content = get_soup_content(\"http://space-facts.com/mars/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling for Mars facts:\n",
    "\n",
    "facts_table = facts_content.find(id=\"tablepress-mars\")\n",
    "\n",
    "facts_columns = [title.get_text() for title in facts_table.find_all(\"td\", attrs={\"class\": \"column-1\"})]\n",
    "facts = [description.get_text() for description in facts_table.find_all(\"td\", attrs={\"class\": \"column-2\"})]\n",
    "\n",
    "# Final response:\n",
    "facts_pd = pd.DataFrame([facts], columns =facts_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the content for Mars hemisphere data:\n",
    "hemis_content = get_soup_content(\"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Wrangling for Mars hemisphere data:\n",
    "\n",
    "base_url = \"https://astrogeology.usgs.gov{}\"\n",
    "html_hemis = hemis_content.find_all(class_=\"itemLink\")\n",
    "\n",
    "storage = {}\n",
    "url_list = [base_url.format(link[\"href\"]) for link in html_hemis if memoized(link[\"href\"], storage)]\n",
    "\n",
    "wide_image_list = []\n",
    "for url in url_list:\n",
    "    hemis_image_wide = get_soup_content(url)\n",
    "    wide_image_list.append(base_url.format(hemis_image_wide.find(class_=\"wide-image\")[\"src\"]))\n",
    "\n",
    "title_list = [title.get_text() for title in hemis_content.find_all(\"h3\")]\n",
    "\n",
    "# Final response:\n",
    "hemis_dic = [{\"title\": key, \"img_url\": value} for (key, value) in list(zip(title_list, wide_image_list))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
